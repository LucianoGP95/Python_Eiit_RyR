{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% pip install openpyxl\n",
    "import os, re, configparser\n",
    "import pandas as pd\n",
    "from globals import glob\n",
    "import os, re\n",
    "import pandas as pd\n",
    "from globals import glob\n",
    "from utilities_database import prepare_data, prepare_database, consult_database, clear_databases, retrieve_data, rename_index, get_date, get_sigma\n",
    "from utilities_analysis import limits_generator, ini_generator_personalized, RyR, z_score_filter, reset_df\n",
    "from utilities_plotting import plot_scatter, plot_capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_calculator(MEAS: pd.DataFrame, lenses_per_nest: int=None) -> pd.DataFrame:\n",
    "    \"\"\"Calculate the desired means.\n",
    "    Parameters:\n",
    "    - MEAS (pd.DataFrame): Input DataFrame containing fiber measurements.\n",
    "    - lenses_per_nest (int, optional): Number of lenses per nest for specific means calculation.\n",
    "    If None, global means are calculated.\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing mean values for fbx and fby.\n",
    "    If lenses_per_nest is specified, it returns specific means for each position.\n",
    "    Notes:\n",
    "    If lenses_per_nest is None:\n",
    "    - Calculates a global mean for fbx and fby.\n",
    "    - Returns the mean values for both fbx and fby in a DataFrame.\n",
    "    - Displays the mean values for fbx and fby.\n",
    "    If lenses_per_nest is specified:\n",
    "    - Calculates specific means for each position for fbx and fby based on the number of lenses per nest.\n",
    "    - Returns a DataFrame containing specific mean values for fbx and fby for each position.\n",
    "    - Displays the specific mean values for fbx and fby per position.\"\"\"\n",
    "    resume = MEAS.transpose().describe() #Transpose the df first due to describe() working in columns.\n",
    "    rough_means = list(resume.iloc[1, :].values)\n",
    "    means = []; means_fbx = []; means_fby = [] #Preallocation\n",
    "    if lenses_per_nest == None: #Calculates a global mean for fbx and for fby\n",
    "        for i, mean in enumerate(rough_means): #Iterates and rounds every mean value\n",
    "            means_fbx.append(mean) if i % 2 == 0 else means_fby.append(mean)\n",
    "            means.append(mean)\n",
    "        abs_mean_fbx = sum(means_fbx) / len(means_fbx)\n",
    "        abs_mean_fby = sum(means_fby) / len(means_fby)\n",
    "        means = [abs_mean_fbx, abs_mean_fby]\n",
    "        means_df = pd.DataFrame()\n",
    "        df_list = []\n",
    "        for _ in range(int(MEAS.shape[0])):  #Iterates over the whole measurements data\n",
    "            nest_data = []\n",
    "            for j in range(len(ordered_means)):\n",
    "                value = float(ordered_means[j])\n",
    "                nest_data.append(value)\n",
    "            nest_df = pd.DataFrame({\"mean\": nest_data})\n",
    "            df_list.append(nest_df)\n",
    "        means_df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    else: #Calculates specific means for each position for fbx and fby\n",
    "        mean_fbx = rough_means[0::2] #Gets fbx values\n",
    "        mean_fby = rough_means[1::2] #Gets fby values\n",
    "        for index in range(lenses_per_nest):\n",
    "            specific_means = mean_fbx[index::lenses_per_nest] #Gets the values of the specific lens for fbx\n",
    "            abs_mean_fbx = sum(specific_means) / len(specific_means)\n",
    "            means_fbx.append(abs_mean_fbx)\n",
    "            specific_means = mean_fby[index::lenses_per_nest] #Gets the values of the specific lens for fby\n",
    "            abs_mean_fby = sum(specific_means) / len(specific_means)\n",
    "            means_fby.append(abs_mean_fby)\n",
    "        means = means_fbx + means_fby\n",
    "        new_order = [0, 3, 1, 4, 2, 5]\n",
    "        ordered_means = [means[i] for i in new_order] #Reorder of the means for implementation\n",
    "        means_df = pd.DataFrame()\n",
    "        df_list = []\n",
    "        for _ in range(int(MEAS.shape[0] / (glob.lenses_per_nest * 2))):  #Iterates over every nest (e.g. 24/6=4 nests)\n",
    "            nest_data = []\n",
    "            for j in range(len(ordered_means)):\n",
    "                value = float(ordered_means[j])\n",
    "                nest_data.append(value)\n",
    "            nest_df = pd.DataFrame({\"mean\": nest_data})\n",
    "            df_list.append(nest_df)\n",
    "        means_df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    return means_df\n",
    "\n",
    "def limits_generator(means_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generate lower and upper tolerance limits based on the means provided in the DataFrame.\n",
    "    Parameters:\n",
    "    - means_df (pd.DataFrame): A DataFrame containing a column 'mean' with mean values for each row.\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with columns 'LO_LIMIT' and 'HI_LIMIT', representing the lower and upper\n",
    "    tolerance limits calculated based on the mean values. The limits are adjusted depending on the row index:\n",
    "    - If the index is even, the limits are calculated with x_tolerance.\n",
    "    - If the index is odd, the limits are calculated with y_tolerance.\"\"\"\n",
    "    x_tolerance = glob.x_tolerance\n",
    "    y_tolerance = glob.y_tolerance\n",
    "    low_limits = []\n",
    "    high_limits = []\n",
    "    for index, row in means_df.iterrows():\n",
    "        if index % 2 == 0:\n",
    "            low_limit = row['mean'] - x_tolerance  #Adjusted calculation based on index parity\n",
    "            high_limit = row['mean'] + x_tolerance\n",
    "        else:\n",
    "            low_limit = row['mean'] - y_tolerance\n",
    "            high_limit = row['mean'] + y_tolerance\n",
    "        low_limits.append(low_limit)\n",
    "        high_limits.append(high_limit)\n",
    "    limits_df = pd.DataFrame({\"LO_LIMIT\": low_limits, \"HI_LIMIT\": high_limits})\n",
    "    return limits_df\n",
    "\n",
    "def ini_generator_personalized(limits_df: pd.DataFrame) -> None:\n",
    "    '''Generates a ini file with personalized limits for every mean'''\n",
    "    class CaseSensitiveConfigParser(configparser.ConfigParser):\n",
    "        '''A custom class to override optionxform and avoid uppercases being converted to lowercase\n",
    "        It just works F76 F76 F76 F76 F76'''\n",
    "        def optionxform(self, optionstr):\n",
    "            return optionstr\n",
    "    config = CaseSensitiveConfigParser()\n",
    "    config.read('../data/template.ini') #Import a template\n",
    "    keys_list = []\n",
    "    for section_name in config.sections(): #Get a keys list with the correct uppercased keys\n",
    "        section = config[section_name]\n",
    "        keys_list.extend(section.keys())\n",
    "    HI_LIMIT = limits_df.iloc[:, 1]\n",
    "    LO_LIMIT = limits_df.iloc[:, 0]\n",
    "    for section in config.sections(): #Iterate through the sections and options in the .ini file\n",
    "        keys_list = list(config[section].keys())\n",
    "        j = 0\n",
    "        for i in range(0, len(keys_list), 2):\n",
    "            key1 = keys_list[i]\n",
    "            key2 = keys_list[i + 1]\n",
    "            col1 = str(limits_df.iloc[j, 1])\n",
    "            col2 = str(limits_df.iloc[j, 0])\n",
    "            j += 1\n",
    "            config[section][key1] = col1\n",
    "            config[section][key2] = col2\n",
    "    for section in config.sections(): #Print the five first elements of the .ini for a quick check\n",
    "        print(f\"[{section}]\")\n",
    "        i = 0\n",
    "        for key, value in config.items(section): \n",
    "            if i < 5:\n",
    "                print(f\"{key} = {value}\")\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "        print(\"...\")\n",
    "    with open(f'../a2_output/{glob.tooling}.ini', 'w') as configfile: #Save the modified data to a new .ini file\n",
    "        for section in config.sections():\n",
    "            configfile.write(f\"[{section}]\\n\")\n",
    "            keys = keys_list #Recover the original keys to write them in the .ini file\n",
    "            for i, key in enumerate(keys):\n",
    "                configfile.write(f\"{key} = {config[section][key]}\\n\")\n",
    "                if (i + 1) % 4 == 0 and i < len(keys) - 1: #Insert a blank line every four keys\n",
    "                    configfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files ready for storage:\n",
      "    TOP_PASSAT_B9_2023y-11m-14d_17h-21m-03s.xlsx\n"
     ]
    }
   ],
   "source": [
    "#File filtering\n",
    "extension = \"xlsx\"\n",
    "file_list = os.listdir(\"../a1_input/\")\n",
    "filtered_list = [filename for filename in file_list if filename.endswith(extension)]\n",
    "print(\"Files ready for storage:\")\n",
    "for file in filtered_list:\n",
    "    print(f\"    {file}\")\n",
    "#pd.read_excel(os.path.join(os.path.abspath(\"../a1_input\"), filtered_list[0]), skiprows = lambda x: x not in specific_rows,)\n",
    "data = pd.read_excel(os.path.join(os.path.abspath(\"../a1_input\"), filtered_list[0])) #Import the RyR generator output\n",
    "df = data.iloc[2:, 1:].reset_index(drop=True) #Slices measures and limits\n",
    "MEAS = reset_df(df.iloc[:, :-2])\n",
    "LIMITS = reset_df(df.iloc[:, -2:])\n",
    "df.reset_index(drop=True, inplace=True) #Reset rows index\n",
    "df.columns = range(df.shape[1]) #Reset columns index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LO_LIMIT</th>\n",
       "      <th>HI_LIMIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.313880</td>\n",
       "      <td>0.338880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.334940</td>\n",
       "      <td>0.364940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.318586</td>\n",
       "      <td>0.343586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.343480</td>\n",
       "      <td>0.373480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326705</td>\n",
       "      <td>0.351705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.351241</td>\n",
       "      <td>0.381241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.313880</td>\n",
       "      <td>0.338880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.334940</td>\n",
       "      <td>0.364940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.318586</td>\n",
       "      <td>0.343586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.343480</td>\n",
       "      <td>0.373480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.326705</td>\n",
       "      <td>0.351705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.351241</td>\n",
       "      <td>0.381241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.313880</td>\n",
       "      <td>0.338880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.334940</td>\n",
       "      <td>0.364940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.318586</td>\n",
       "      <td>0.343586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.343480</td>\n",
       "      <td>0.373480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.326705</td>\n",
       "      <td>0.351705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.351241</td>\n",
       "      <td>0.381241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.313880</td>\n",
       "      <td>0.338880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.334940</td>\n",
       "      <td>0.364940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.318586</td>\n",
       "      <td>0.343586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.343480</td>\n",
       "      <td>0.373480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.326705</td>\n",
       "      <td>0.351705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.351241</td>\n",
       "      <td>0.381241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LO_LIMIT  HI_LIMIT\n",
       "0   0.313880  0.338880\n",
       "1   0.334940  0.364940\n",
       "2   0.318586  0.343586\n",
       "3   0.343480  0.373480\n",
       "4   0.326705  0.351705\n",
       "5   0.351241  0.381241\n",
       "6   0.313880  0.338880\n",
       "7   0.334940  0.364940\n",
       "8   0.318586  0.343586\n",
       "9   0.343480  0.373480\n",
       "10  0.326705  0.351705\n",
       "11  0.351241  0.381241\n",
       "12  0.313880  0.338880\n",
       "13  0.334940  0.364940\n",
       "14  0.318586  0.343586\n",
       "15  0.343480  0.373480\n",
       "16  0.326705  0.351705\n",
       "17  0.351241  0.381241\n",
       "18  0.313880  0.338880\n",
       "19  0.334940  0.364940\n",
       "20  0.318586  0.343586\n",
       "21  0.343480  0.373480\n",
       "22  0.326705  0.351705\n",
       "23  0.351241  0.381241"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_df = mean_calculator(MEAS, glob.lenses_per_nest)\n",
    "limits_generator(means_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
